# Lecture 7 内存管理 *Memeory Management*

**Outline**：

- 内存寻址
- 段式寻址
- 页式寻址
- 页框管理
- 内存区管理
- 非连续内存区管理
- 页替换策略

-------



## 1. 内存寻址

#### 1.1 内存地址分类

​		以80x86微处理器为例，具有三种类型的地址

- **逻辑地址**：在机器语言指令中被使用
- **虚拟地址**（线性地址）：32位的无符号数可以寻址最多4GB的内存（ $2^{32} bytes = 4GB$ ）
- **物理地址**：32-bit的无符号整数，**用于内存芯片中寻址内存单元**

---------

#### 1.2 分段和分页

- **分段：给每一个进程分配不同的虚拟地址空间**
- **分页：把线性地址空间映射到不同的物理地址空间**

-------



## 2. 段式寻址

#### 2.1 硬件段式寻址

- 逻辑地址的构成：
    - **段ID/段选择符**：16-bit
        - 其中的index查表找是哪一段，**基址**
    - **偏移量**：32-bit

<img src="./pic/截屏2021-06-20 下午3.32.49.png" alt="avatar" style="zoom:40%;" />

- **段选择符**：
    - Index：段描述符的index
    - TL (table indicator)：指明index是gdt（全局描述符表）还是ldt（局部描述符表）的index
    - RPL（特权等级，Requestor Privilege Level）
- **段寄存器**：
    - **存储段选择符**
    - 特定用途的段寄存器：CS（代码段）、SS（堆栈段）、DS（数据段）
    - 通用段寄存器：es、fs、gs
- **段描述符**：8-byte
    - **存放在GDT或LDT中**
    - GDT和LDT在内存中存放的地址和大小存放在**处理器控制寄存器gdtr、ldtr中**
    - 字段：
        - Base：32-bit的线性地址
        - G granularity：1-bit，表征段的大小是以字节为单位还是4KB为单位
        - Limit：20-bit的偏移量
        - S system flag：1-bit，表征是否为系统段
        - Type：4-bit，表示为代码段、数据段还是系统段等
        - DPL：描述符特权等级，2-bit，限制对段的访问和存取
        - Segment-present flag：1-bit，是否在内存中
        - ...
- 段描述符的快速访问：
    - 80x86为6个可编程的段寄存器的每一个都提供了一个额外的不可编程的寄存器
    - 每次加载段选择符的时候，会**把相应的段描述符(8-bit)由内存加载到不可编程的寄存器中**
        - 因此，**针对那个段的逻辑地址转换可以不访问内存中的GDT或者LDT**
- **逻辑地址到线性地址的转换**：
    - 段选择符中的index + 根据段选择符中的TL确定的是位于gdt还是ldt -> **访问响应描述符表的指定位置，得到基址**
    - **基址与偏移量组合得到线性地址**

<img src="./pic/截屏2021-06-20 下午3.47.00.png" alt="avatar" style="zoom:40%;" />

-------------

#### 2.2 Linux段式寻址

- **Linux更倾向于分页而不是分段**：**内存管理较为简单**，且**具有更好的系统结构兼容性**，仅在必要时采用分段机制
- Linux使用4个主要的段：
    - 内核代码段：`_KERNEL_CS macro`
    - 内核数据段：`_KERNEL_DS macro`
    - 用户代码段：`_USER_CS marco`
    - 用户数据段：`_USER_DS marco`
- Linux GDTs：
    - **每个CPU一个GDT**，存储在cpu_gdt_table数组中，其在内存中的地址及大小存储在cpu_gdt_descr数组中
    - 每个GDT包含18个段描述符：其中包含4个用户/内核的代码/数据段的段描述符，和一个默认的LDT default_ldt数组
- Linux LDTs：
    - **缺省LDT：存储在default_ldt数组中**，包含5个entries，但Linux目前仅有效使用其中的两个
    - **调用门：80x86微处理器提供的改变CPU特权等级的机制**
    - **大多数用户态下的Linux程序不再使用LDT！**

---------



## 3. 页式寻址

#### 3.1 硬件页式寻址

- **硬件分页机制**：

    - **页**Pages：**确定长度的线性地址空间**，对应的是虚拟地址空间中的概念
    - **页框**Page frames：**内存被切分为确定长度的块**，对应的是物理地址空间中的概念
    - **80x86处理器中可以通过设置控制寄存器cr0中的PG标志来启用分页机制**

- **规则分页**：

    - **4KB的页**：线性地址：32-bit

        - **页目录 Directory**：10 bits
        - **页表 Table**：10 bits
        - **偏移量 Offset**：12 bits

    - **两步转换机制**：

        - 每个进程都有自己的分页转换，原因是进程之间的地址空间相互独立，且可能会有共享内存

        - 页目录：**页目录的物理地址存放在cr3寄存器中**

        - 页表

        - **逻辑地址转换成物理地址的过程**：（这里以一级页表为例，多级页表类似）

            - 用页号P去检索页表，从页表中得到该页对应的物理块号，把它装入物理地址寄存器中
            - 将页内地址D直接送入物理地址寄存器的块内地址字段
            - 物理地址寄存器中得到实际需要访问内存的地址

        - 注意，如果是2级页表，32位地址分为10, 10,12这3部分。则，页目录表1024项，每个小页表也是1024项，实际的存储空间是1024*4k(所有小页表大小)+4k(页目录大小)

        - **虚拟地址连续，物理地址不一定连续**

        - 总寻址大小：1024 * 1024 = 1M 个页表项，共4GB大小（页大小为4KB）

        - 为啥说多级页表可以节省内存空间咧？

            - 实际上，**一个进程并不是所有线性地址都会映射到页表中**，假如所有页表都映射，的确多级页表占用了更多的内存，但是**大多数地址都是没有映射的**。

                如果是一级页表，因为页表是一个大数组，如果在初始化的时候没有分配好足够的空间，以后要扩展的话怎么办？所以**一级页表在初始化的时候便分配了全部的连续内存，即使并不是所有地址都映射到页表上**。

                如果是多级页表，这里以二级页表为例。**在初始化的时候只需要先分配好页目录所需的连续内存，页表的内存可以到需要使用的时候再动态分配**，增加了**灵活性**，同时**节省了内存**。

    <img src="./pic/截屏2021-06-20 下午4.12.31.png" alt="avatar" style="zoom:40%;" />

    - 页目录项和页表项的结构：
        - **页框物理地址的高20位. 20-MSB**（MSB: most significant bits）
            - 存储页框物理地址的高20位，原因是只要找到物理地址的高20位，再将虚拟地址的后12位直接拼接在后面，就是物理地址
        - presnt标志：是否位于内存中（页表在使用时位于内存中，但也有可能是虚拟内存）

- **扩展分页**：

    - 原因：**减少存储空间**（不用存储页目录项）+ **连续地址分配性能好**

    <img src="./pic/截屏2021-06-20 下午4.28.38.png" alt="avatar" style="zoom:30%;" />

    - 用于翻译**大而连续**的线性地址，**页的大小为4MB**（原因是offset增加了10位）
    - 10-MSB

- 分页的硬件保护方案：

    - 和页以及页表相关的特权等级只使用了2个
    - 页访问权限只有两种：使用read/write标志位

- **物理地址扩展 PAE 的分页机制**：

    - 原因：地址引脚线增加到36，可支持64GB内存的寻址（设置cr4控制寄存器中的PAE标志位来启动）
    - 变化：
        - **物理地址从32位变成了36位**
        - **页表项对应的位从20位变成了24位**，offset的位数不变
        - **每个页表项从32位增长为64位，因此一个页表只能包含512个表项（原来可以1024个）**
            - 原因：64GB的RAM被分为2^24个页框，**页表项的物理地址字段从20位扩展到24位**，**每个页表项必须包含12个标志位（固定）和24个物理地址位（36-12），共36位**，因此，每个页表项须从32位扩展到64位（36位>32位，考虑到**对齐**，因此应将页表项扩大一倍到64位）
        - **增加了一级页表 PDPT（Page Directory Pointer Table）**：
            - 包含4个64-bit的项，**指向不同的页目录项**
            - cr3寄存器包含27-bit的PDPT基址
        - 注意，**每个进程仍只能看到4GB内存**，仍为32位地址
            - 当映射4KB的页时：
                - Bits 31-30: 指向PDPT的项 (2 bits)
                - Bits 29-21: 指向页目录的项 (9 bits)（从10 bits变成9 bits，原因是页目录中的页表项变成512个）
                - Bits 20-12: 指向页表的项 (9 bits)
                - Bits 11-0: 偏移量 (12 bits)
            - 当映射2MB的页时：
                - Bits 31-30: 指向PDPT的项
                - Bits 29-21: 指向页目录的项（减少了1位）
                - Bits 20-0: 偏移量（减少了1位，大页的大小减小）

    <img src="./pic/截屏2021-06-20 下午4.53.04.png" alt="avatar" style="zoom:40%;" />

    - 相较于之前的提升点在于：
        - 新增对页目录项进行的寻址（利用PDPT），**提高了查找效率**
        - **物理地址空间扩展**，页的总数目增多（原因是地址扩展）
        - 仍向下兼容32位的寻址（如上介绍）

- 64位体系结构的分页：两级分页已不再适用，使用几级分页取决于处理器的类型
- **TLB**：Translation Lookaside Buffers，转译后备缓冲区
    
    - TLB其实就是一块**高速缓存**。数据cache缓存地址(虚拟地址或者物理地址)和数据。TLB缓存虚拟地址和其映射的物理地址。TLB根据虚拟地址查找cache，它没得选，只能根据虚拟地址查找。所以TLB是一个虚拟高速缓存。硬件存在TLB后，虚拟地址到物理地址的转换过程发生了变化。**虚拟地址首先发往TLB确认是否命中cache，如果cache hit直接可以得到物理地址**。否则，一级一级查找页表获取物理地址。并将虚拟地址和物理地址的映射关系缓存到TLB中。

--------

#### 3.2 Linux页式寻址

- **四级分页机制**：
    - 页全局目录 Page Global Directory
    - 页上级目录 Page Upper Directory
    - 页中级目录 Page Middle Directory
    - 页表 Page Table

<img src="./pic/截屏2021-06-20 下午4.58.58.png" alt="avatar" style="zoom:40%;" />

- Linux中的分页：
    - 如果不使用PAE, 二级分页已足够使用（Linux忽视页上级目录和页中级目录字段）

---------



## 4. 页框管理

#### 4.1 Basic

- 两种页框大小：
    - 4KB：标准的内存管理单元
    - 4MB
- **页描述符 Page Descriptors**：**实际上是页框的描述符！！**
    - 类型：Page（32 bytes）
    - 存储在 `mem_map` 数组中，需要的空间略小于整个内存空间的1%（32 bytes / 4KB ~ 1%）
    - 字段：
        - Flags：一组标志位，**状态信息**
            - 页框的状态标志：一系列相应的宏定义
        - _count：**页框引用数**，表示**被多少个进程引用**
        - _mapcount：**映射到该页框的页表项的数量**，可能由动态链接库 + 进程通讯（共享内存）的形式导致
        - ...
- **非一致性内存访问 NUMA**：
    - **物理内存被切分位多个节点Nodes，每个节点有一个描述符（节点描述符）Table 8-3**
    - **每个节点的物理内存进一步划分为多个管理区**，**每个区也有一个描述符（管理区描述符）Table 8-4**
    - **节点描述符 Node Descriptor**：
        - 节点描述符的类型：`pg_data_t`
        - 部分字段：
            - `struct zone[] node_zones`：该节点下管理区描述符的列表
            - `struct zonelist[] node_zonelists`：该节点下管理区数据结构的列表
            - `int nr_zones`：该节点下管理区的数目
            - ...
    - **管理区描述符 Zone Descriptor**:
        - 管理区描述符的类型：`zone`
        - 部分字段：
            - `unsigned long free_pages`：管理区内空闲页的数目
            - `unsigned long pages_min`：管理区保留使用的页的数目
            - `unsigned long pages_low`：重声明的页框的低水印
            - `unsigned long pages_high`：重声明的页框的高水印
            - ...
- **保留页框池**：
    - **有些内核控制路径在请求内存时不允许被阻塞**，即**原子分配请求**。因此，**内核保留了部分页框**供原子内存分配请求使用
    - 保留内存的大小存放在 *min_free_kbytes* 变量中 (单位 :kilobytes)

-------

#### 4.2 分区页框分配器 Zoned Page Frame Allocator

- **页框分配在内核里的机制我们叫做分区页框分配器**，在linux系统中，**分区页框分配器管理着所有物理内存，无论你是内核还是进程，都需要请求分区页框分配器，这时才会分配给你应该获得的物理内存页框**。当你所拥有的页框不再使用时，你必须释放这些页框，让这些页框回到管理区页框分配器当中。
- 注意，page frame cache 和之前的保留页框池没有必然联系
- **Per-CPU 页框缓存**：
    - 每一个per-CPU页框缓存包含了**一些预先申请的页框**，这些页框**用以加速单个内存页分配请求**
    - **`per_cpu_pages` 描述符**：
        - 可以分配、释放页框
        - 字段：
            - `int count`：cache中的页框数目
            - `int low`：最少的页框数目的水印
            - `int high`：最多的页框数目的水印
            - `int batch`：从cache中增加或减少的页框数目
            - `strcut list_head list`：cache中页框描述符（页描述符）的列表
        - 如果页框的数量< **low**, kernel从伙伴系统中申请**batch** 个单独的页框来补充对应的高速缓存
        - 如果页框的数量> **high**, kernel从缓存中释放**batch**个页 框回到伙伴系统

<img src="./pic/截屏2021-06-20 下午5.27.47.png" alt="avatar" style="zoom:30%;" />

---------

#### 4.3 伙伴系统 Buddy System

- 两种避免外碎片的方法：

    - **使用分页单元将不连续的空闲页框映射为连续的线性地址**
    - **尽量避免为满足小的空间需求而将大的连续空闲内存块切分的情况**
    - **Linux不使用分页技术避免外碎片**，原因是：
        - **有时候分配连续的内存页框是必要的**
        - 具有保持内核页表不变的优势
        - 内核可以通过使用4MB大小的页来访问大块连续的物理内存

- 伙伴系统的**构成**：

    - **11个内存块的链表: 大小为1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024个连续页框的内存块**

- **什么时候两个内存块是伙伴**？

    - **大小相同** (b)，**物理地址连续**，第一个块的第一个页框的物理地址是 $b \times 2^{12}$ 的倍数

    <img src="./pic/截屏2021-06-20 下午5.40.14.png" alt="avatar" style="zoom:40%;" />

- 伙伴系统的数据结构：

    - 一个包含11个类型为*free_area*元素的数组，每个元素对应于1个块大小
        - 该数组存放在管理区描述符的*free_area* 字段
        - **管理区描述符中*free_area*数组的第*k*个元素管理所有大小为 $2^k$ 的空闲内存块**
        - **该元素的*free_list*字段是一个双向循环链表的表头**。**该链表管理所有大小为 $2^k$ 个页框的空闲内存区的页描述符**

    <img src="./pic/截屏2021-06-20 下午5.49.56.png" alt="avatar" style="zoom:40%;" />

- **仍存在外碎片化的问题**：

<img src="./pic/截屏2021-06-20 下午5.51.14.png" alt="avatar" style="zoom:30%;" />

​		原因是相邻内存块的大小不同，不再是伙伴，因此不能再进行合并！

- 解决方案：**迁移类型**

    - 反碎片法 Anti-Fragmentation，利用迁移类型来实现
    - 迁移类型是**按照页块(PageBlock)来划分**的，**一个页块正好是页面分配器最大的分配大小**，即2的MAX_ORDER-1次方，通常是**4MB**。（MAX_ORDER=11，$2^{10} \times 4KB = 4MB$）
    - 类型：
        - **不可移动类型 UNMOVABLE**：其特点是在内存中有固定位置，不能移动到其他地方
        - **可移动类型 MOVABLE**：表示可以随意移动的页
        - **可回收的页 RECLAIMABLE**：这些页不能直接移动，但是可以回收
    - **不可移动页不允许在可移动页的中间申请，避免导致碎片**

    <img src="./pic/截屏2021-06-20 下午6.04.19.png" alt="avatar" style="zoom:50%;" />

---------



## 5. 内存区管理

#### 5.1 Slab分配器

- 一种内存分配机制
- 内碎片：已经被分配出去（能明确指出属于哪个进程）却不能被利用的内存空间，当只申请一小块内存空间（如描述符、锁）时容易产生
- Slab分配器中的假设：
    - **内核函数通常反复地申请相同类型的内存区**（例如申请进程描述符的存储空间）
    - **内存区的申请请求可以根据他们的频率分类**
    - 伙伴系统的函数调用会“污染”硬件缓存，从而增加平均内存访问时间
- Slab分配器的结构：
    - **将内存区看做对象*objects.* 对象包含一组数据结构或一系列的操作函数，如*constructor*和 *destructor***，Object的描述符类型为 `kmem_bufctl_t`
        - 一个object描述符包含**该slab中下一个空闲object的 index**, 实现了**slab内部空闲object的一个简单队列**
    - **将object组织为*caches***，描述符类型为 `kmem_cache_t`
        - 每一个cache用来存储同样类型的object
        - 每一个*cache*划分为*slabs*，描述符类型为 `slab`，**相同slab内的对象类型相同！例如全为task_struct**
            - 三种状态：
                - **满的**：slab 中的所有对象被标记为使用。
                - **空的**：slab 中的所有对象被标记为空闲。
                - **部分**：slab 中的对象有的被标记为使用，有的被标记为空闲。
        - 每一个slab由1个或者多个连续的页框组成，其中包含已分配和空闲的*objects*
- 这里的对象就是指具体相同的数据结构和大小的某个内存单元。比方上面所说的mm_struct结构体。我们知道，内核每创建一个进程时就需要给其分配mm_struct，这样一来内核中需要维护这个结构体的数目是相当多的，**如果全部使用buddy分配器来分配，那么将会产生大量的碎片**。而且，这种结构体在内核中分配和释放的频率是很高的，每分配一次又需要对它初始化，用过以后又需要释放，对系统的性能影响也很大。
- slab分配的最小和最大内存单元是多少？最小的是32KB，最大分配单元依赖体系架构。
- slab分配器是否依赖buddy系统？我的回答是肯定的。诚然，slab系统与buddy系统所要解决的问题是互补的，一个解决外部碎片一个解决内部碎片，但事实上，**slab在新建cache时同样需要用到buddy来为之分配页面，而在释放cache时也需要buddy来回收这此页面**。也就是说，**slab事实上是依赖buddy系统的**。
- 内核在初始化的时候根据kmalloc_sizes.h文件中定义的对象的大小，初始化了管理这些对象的slab，以及相关kmem_cache。 
- **相同类型的对象归为一类(如进程描述符就是一类)，每当要申请这样一个对象，slab分配器就从一个slab列表中分配一个这样大小的单元出去，而当要释放时，将其重新保存在该列表中，而不是直接返回给伙伴系统，从而避免这些内碎片**。slab分配器并不丢弃已分配的对象，而是释放并把它们保存在内存中。当以后又要请求新的对象时，就可以从内存直接获取而不用重复初始化。

<img src="./pic/截屏2021-06-20 下午8.26.07.png" alt="avatar" style="zoom:50%;" />

- Slab分配器的优点：
    - 节约空间，缓解了内碎片
    - slab里面的objects已经初始化好了（给每个字段赋初始值，很慢），节约时间

<img src="./pic/截屏2021-06-20 下午8.06.51.png" alt="avatar" style="zoom:40%;" />

- Slab分配器的缺点：
    - 缓存队列管理复杂；
    - 管理数据存储开销大

- 何时分配和释放？
    - **在cache中创建新的slab**：当请求分配一个新的object，但Cache中并不包含空闲的object时
    - **在cache中释放slab**：当cache中存在太多的空闲object时。有一个定时函数周期性地检查Cache中是否有可以被释放的完全空闲的Slab
- **内存池**：专门用来支持Slab分配器

--------



## 6. 非连续内存区管理

- 为了避免外碎片的产生
- 描述符类型:*vm_struct*
- get_vm_area(): 寻找线性地址中的一个空闲区域
- 分配/释放一个非连续内存区：`vmalloc() / vfree()`

-------



## 7. 页替换策略

- 理想策略：所淘汰的页应 该是**以后不再访问的页**或**距现在最长时间后再访问的页**。这样的调度算法使缺页中断率为最低，但无法实现

- **随机页面替换算法**：要淘汰的页面是由一个随机数产生程序所产生的随机数来确定，**一般不采用**

- **先进先出页面替换算法(FIFO)**：一种**低开销**的页面替换算法，基于**程序总是按线性顺序来访问物理空间这一假设**。注意，内存中常驻的页不参与！

- **最近最少用页面替换算法(LRU)**：淘汰的页面是在最近一段时间里较久未被访问的那一页，根据程序执行时所具有的局部性的特征决定

- **第二次机会页面替换算法**：对FIFO算法进行改进,把FIFO算法与页表中的“引用位 ”结合起来使用。**最先进入主存的页面，如果最近还在被使用的话，仍有机会像一 个新调入页面一样留在主存中。**

    - 检查FIFO中的队首页面(这是最早进入主存的页面)，如果它的 “引用位”是0，那么该页面既老又没有用，淘汰;
    - 如果“引用位”是1，说明虽然它进入主存早，但最近仍在使用。于是把它的“引用位”清成0，并把这个页面移到队尾， 把它看作是新调入的页。

- **时钟页面替换算法**：与第二次机会差不多，**指针当前指向的位置被认为是最老的页**

    -   一个页面首次装入主存时，其“引用位”置0
    - 在主存中的任何页面被访问时，其“引用位”置1
    - 淘汰页面时，存储管理**从指针当前指向的页面开始扫描循环队列**，把所见到的**“引用位”是1的页面的“引用位”清0**， 并跳过这个页面；**把“引用位”是0的页面淘汰掉，指针推进一步，将新进来的页放在空出来的位置，并把引用位置1**
    - 扫描循环队列时，如果所有页面的“引用位”都为1，指针 就会绕整个队列一圈，把所有页面的“引用位”清0;指针 停在起始位置，并淘汰掉这一页，然后，指针推进一步

- **改进时钟页面替换算法**：如果把页表中的“引用位”和“修改位”结合起来使 用，共可以组合成四种情况：最近没有被引用，没有被修改(r=0,m=0)、...

    - **第一次尝试：不改变位，仅尝试转动指针寻找r=0、m=0的页**
    - **第二次尝试：尝试查找r=0、m=1的页，并将遇上的所有r置0**
    - **第三次尝试：重复第一步的操作，最多再重读一次第二步的操作，一定可以找出最佳淘汰页面**

- **LRU-K算法**：维护两个队列，记录所有缓存数据被访问的历史

    - LRU-K的主要目的是为了解决LRU算法“缓存污染”的问题，其核心思想是将“最近使用过1次”的判断标准扩展为“最近使用过K次”。
    - 相比LRU，LRU-K需要多维护一个队列，用于记录所有缓存数据被访问的历史。只有当数据的访问次数达到K次的时候，才将数据放入缓存。当需要淘汰数据时，**LRU-K会淘汰第K次访问时间距当前时间最大的数据**。
    - 过程：
        - 数据第一次被访问，加入到**访问历史列表**；
        - 如果数据在访问历史列表里后没有达到K次访问，则按照一定规则（FIFO，LRU）淘汰；
        - 当访问历史队列中的数据访问次数达到K次后，将数据索引从历史队列删除，将数据移到**缓存队列**中，并缓存此数据，缓存队列重新按照时间排序；
        - 缓存数据队列中被再次访问后，重新排序；
        - 需要淘汰缓存队列中的数据时，淘汰缓存队列中排在末尾的数据，即：淘汰“倒数第K次访问离现在最久”的数据。

    - LRU-K具有LRU的优点，同时能够避免LRU的缺点，实际应用中**LRU-2是综合各种因素后最优的选择**，LRU-3或者更大的K值命中率会高，但适应性差，需要大量的数据访问才能将历史访问记录清除掉。

- **Two Queues** (2Q)：

    - 维护两个队列，一个FIFO，一个LRU，参照LRU-K的思想
